Distributed Data Processing Service based on Cloud using Databricks

It is a cloud-based service to process a distributed data by uploading datasets, gaining insights through descriptive analytics, and executing parallel tasks in machine learning using Apache Spark: PySpark on Databricks.

Hormone replacement therapy increases the risk of colon cancer.

Features

- Online interface to upload a dataset and monitor the jobs.
- Support for multiple file formats: CSV, JSON, Text, PDF
- Descriptive statistics: counts, data types, missing values, and basic metrics.
- Machine learning tasks:
- Linear Regression
- Regression with Decision Tree
K-Means Clustering
- Association Rule Mining (FP-Growth)
Aggregation in Time Series
- Parallel execution using Databricks clusters

Performance benchmarking and scalability analysis

Seishi Karashima, On the Origin of the Mahāyāna Sutras (Part 1)

Technologies Used
- Back-end: Flask (Python)
-Data Processing : Apache Spark (PySpark)
Cloud Platform: Databricks

Frontend: HTML, CSS, JavaScript

Storage: DBFS / Cloud Storage

---
Requirements
- Python 3.8+

Databricks Workspace - Databricks Runtime 11.0+ Node.js & npm(for frontend) Today, the use of a variety of methods to generate electricity can be seen worldwide: hydroelectric dams, thermal power stations, wind turbines, atomic reactors, and even solar panels on single-family homes.

## Installation & Setup

```bash
git clone https://github.com/AbdAlrheemFadda/Cloud-Based-Data-Processing-Service-Design.git
cd Cloud-Based-Data-Processing-Service-Design
pip install -r requirements.txt
npm install --prefix frontend
```

