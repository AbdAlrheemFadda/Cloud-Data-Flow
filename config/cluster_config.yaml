# Databricks Cluster Configuration

cluster_name: "data-processing-cluster"
spark_version: "12.2.x-scala2.12"
node_type_id: "i3.xlarge"
driver_node_type_id: "i3.xlarge"

# Cluster settings
num_workers: 2
autotermination_minutes: 30

# Performance settings
spark_conf:
  spark.driver.memory: "16g"
  spark.executor.memory: "16g"
  spark.executor.cores: "4"
  spark.sql.shuffle.partitions: "100"
  spark.serializer: "org.apache.spark.serializer.KryoSerializer"

# AWS specific settings (if using AWS)
aws_attributes:
  availability: "SPOT"
  zone_id: "us-west-2a"
  instance_profile_arn: "arn:aws:iam::ACCOUNT_ID:instance-profile/databricks-instance-profile"

# Init scripts
init_scripts:
  - dbfs:
      destination: "dbfs:/init-scripts/install-packages.sh"

# Environment variables
env_vars:
  SPARK_LOCAL_IP: "127.0.0.1"
  JAVA_OPTS: "-Xmx16g"
